{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Project 5 Instructions - Ensemble ML, Spiral (Wine)\n",
    "**Author:** AARON \n",
    "**Date:** November 19, 2025 \n",
    "**Objective:** Gain an understanding of ensemble model collections.  Evaluate two collection of models and document peformance metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "- Gain an understanding of ensemble model collections.  Evaluate two collection of models and document peformance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "source": [
    "\n",
    "## Section 1. Import and Inspect the Data\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489b4cca",
   "metadata": {},
   "source": [
    "### 1.1 Include Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44173dd6",
   "metadata": {},
   "source": [
    "### 1.2 Load the dataset and display basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the dataset (download from UCI and save in the same folder)\n",
    "df = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "\n",
    "# Display structure and first few rows\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "source": [
    "## Section 2. Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "402c7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function that:\n",
    "\n",
    "# Takes one input, the quality (which we will temporarily name q while in the function)\n",
    "# And returns a string of the quality label (low, medium, high)\n",
    "# This function will be used to create the quality_label column\n",
    "def quality_to_label(q):\n",
    "    if q <= 4:\n",
    "        return \"low\"\n",
    "    elif q <= 6:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "\n",
    "# Call the apply() method on the quality column to create the new quality_label column\n",
    "df[\"quality_label\"] = df[\"quality\"].apply(quality_to_label)\n",
    "\n",
    "\n",
    "# Then, create a numeric column for modeling: 0 = low, 1 = medium, 2 = high\n",
    "def quality_to_number(q):\n",
    "    if q <= 4:\n",
    "        return 0\n",
    "    elif q <= 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "df[\"quality_numeric\"] = df[\"quality\"].apply(quality_to_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91b7deb",
   "metadata": {},
   "source": [
    "## Section 3. Feature Selection and Justification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2b9ab3",
   "metadata": {},
   "source": [
    "### 3.1 Define X and y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "891a0dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input features (X) and target (y)\n",
    "# Features: all columns except 'quality' and 'quality_label' and 'quality_numberic' - drop these from the input array\n",
    "# Target: quality_label (the new column we just created)\n",
    "X = df.drop(columns=[\"quality\", \"quality_label\", \"quality_numeric\"])  # Features\n",
    "y = df[\"quality_numeric\"]  # Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95c11e5",
   "metadata": {},
   "source": [
    "### Reflection 3:\n",
    "- I combine numbers into low, medium, and high categories.  This allows all the different models focus on three target areas.  This helps with overfitting and giving the classifier well defined boundaries. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddefc767",
   "metadata": {},
   "source": [
    "## Section 4. Split the Data into Train and Test\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c3ef051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (stratify to preserve class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a7c05c",
   "metadata": {},
   "source": [
    "## Section 5.  Evaluate Model Performance (Choose 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83ce15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to train and evaluate models\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, results):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average=\"weighted\")\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"\\n{name} Results\")\n",
    "    print(\"Confusion Matrix (Test):\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"Model\": name,\n",
    "            \"Train Accuracy\": train_acc,\n",
    "            \"Test Accuracy\": test_acc,\n",
    "            \"Train F1\": train_f1,\n",
    "            \"Test F1\": test_f1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8abfe2",
   "metadata": {},
   "source": [
    "### 5.1a Gradient Boosting (100)\n",
    "- Below I run the Gradient Boosting Classifier with n_estimators at 100 and learning_rate at 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed20995f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting (100, 0.1) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  3 247  14]\n",
      " [  0  16  27]]\n",
      "Train Accuracy: 0.9601, Test Accuracy: 0.8562\n",
      "Train F1 Score: 0.9584, Test F1 Score: 0.8411\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting 100, 0.01\n",
    "\n",
    "results = []\n",
    "evaluate_model(\n",
    "    \"Gradient Boosting (100, 0.1)\",\n",
    "    GradientBoostingClassifier(\n",
    "        n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42\n",
    "    ),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3302f4",
   "metadata": {},
   "source": [
    "### 5.1b Gradient Boosting (175)\n",
    "- Below I run the Gradient Boosting Classifier with n_estimators at 175 and learning_rate at 0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96076c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting (175, 0.03) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  1  12   0]\n",
      " [  2 250  12]\n",
      " [  0  16  27]]\n",
      "Train Accuracy: 0.9281, Test Accuracy: 0.8688\n",
      "Train F1 Score: 0.9222, Test F1 Score: 0.8546\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting 175, 0.03\n",
    "\n",
    "\n",
    "evaluate_model(\n",
    "    \"Gradient Boosting (175, 0.03)\",\n",
    "    GradientBoostingClassifier(\n",
    "        n_estimators=175, learning_rate=0.03, max_depth=3, random_state=42\n",
    "    ),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae60f1e3",
   "metadata": {},
   "source": [
    "### 5.1c Reflection on Gradient Boosting\n",
    "- I think a well defined improvement was made by increasing the n_estimators to 175 and decreasing the learning_rate to 0.03.  I see a Test Accuracy and Test F1 Score improvement of > 1%, an accurate prediction for one \"low\" classification, and a 3% drop in the Train Accuracy and Train F1 Score.  \n",
    "- I gain accuracy and reduce the difference between the Train and Test metrics from 10% to 6%.  This in turn leads to less overfitting.  \n",
    "- I feel this is a great addition to this model and something to keep in mind.  Namely, adjust the parameters of the model to get a good balance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e75df6",
   "metadata": {},
   "source": [
    "### 5.2a Voting (RF 100 + LR 1K + KNN)\n",
    "\n",
    "- Below I run the Voting Classifier with n_estimators at 100 and max_iter at 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9b72fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Voting (RF 100 + LR 1K + KNN) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 258   6]\n",
      " [  0  27  16]]\n",
      "Train Accuracy: 0.9179, Test Accuracy: 0.8562\n",
      "Train F1 Score: 0.9010, Test F1 Score: 0.8236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Repos\\applied-ml-hrawp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Voting Classifier (RF 100, LR 1K, KNN) \n",
    "voting2 = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"RF\", RandomForestClassifier(n_estimators=100)),\n",
    "        (\"LR\", LogisticRegression(max_iter=1000)),\n",
    "        (\"KNN\", KNeighborsClassifier()),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "evaluate_model(\n",
    "    \"Voting (RF 100 + LR 1K + KNN)\", voting2, X_train, y_train, X_test, y_test, results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561b40c4",
   "metadata": {},
   "source": [
    "### 5.2b Voting (RF 100 + LR 1K + KNN)\n",
    "\n",
    "- Below I run the Voting Classifier with n_estimators at 300 and max_iter at 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a4e3d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Voting (RF 300 + LR 2K + KNN) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  1 258   5]\n",
      " [  1  23  19]]\n",
      "Train Accuracy: 0.9124, Test Accuracy: 0.8656\n",
      "Train F1 Score: 0.8977, Test F1 Score: 0.8391\n"
     ]
    }
   ],
   "source": [
    "# Voting Classifier (RF - 300, LR 2K, KNN) \n",
    "\n",
    "voting3 = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"RF\", RandomForestClassifier(n_estimators=300)),\n",
    "        (\"LR\", LogisticRegression(max_iter=2000)),\n",
    "        (\"KNN\", KNeighborsClassifier()),\n",
    "    ],\n",
    "    voting=\"hard\",\n",
    ")\n",
    "evaluate_model(\n",
    "    \"Voting (RF 300 + LR 2K + KNN)\", voting3, X_train, y_train, X_test, y_test, results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4ba9ac",
   "metadata": {},
   "source": [
    "### Section 6. Compare Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28f2f974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of All Models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Test Acc_Diff</th>\n",
       "      <th>Train-Test Acc_Diff</th>\n",
       "      <th>Train-Test F1_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting (175, 0.03)</td>\n",
       "      <td>0.928069</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.922212</td>\n",
       "      <td>0.854639</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.059319</td>\n",
       "      <td>0.067573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting (RF 300 + LR 2K + KNN)</td>\n",
       "      <td>0.912432</td>\n",
       "      <td>0.865625</td>\n",
       "      <td>0.897654</td>\n",
       "      <td>0.839116</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.046807</td>\n",
       "      <td>0.058538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting (100, 0.1)</td>\n",
       "      <td>0.960125</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.958410</td>\n",
       "      <td>0.841106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103875</td>\n",
       "      <td>0.117304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting (RF 100 + LR 1K + KNN)</td>\n",
       "      <td>0.917905</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.901043</td>\n",
       "      <td>0.823627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061655</td>\n",
       "      <td>0.077416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model  Train Accuracy  Test Accuracy  Train F1  \\\n",
       "1  Gradient Boosting (175, 0.03)        0.928069       0.868750  0.922212   \n",
       "3  Voting (RF 300 + LR 2K + KNN)        0.912432       0.865625  0.897654   \n",
       "0   Gradient Boosting (100, 0.1)        0.960125       0.856250  0.958410   \n",
       "2  Voting (RF 100 + LR 1K + KNN)        0.917905       0.856250  0.901043   \n",
       "\n",
       "    Test F1  Test Acc_Diff  Train-Test Acc_Diff  Train-Test F1_Diff  \n",
       "1  0.854639       0.012500             0.059319            0.067573  \n",
       "3  0.839116       0.009375             0.046807            0.058538  \n",
       "0  0.841106       0.000000             0.103875            0.117304  \n",
       "2  0.823627       0.000000             0.061655            0.077416  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a table of results \n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df[\"Test Acc_Diff\"] = results_df[\"Test Accuracy\"] - results_df.loc[0, \"Test Accuracy\"]\n",
    "results_df[\"Train-Test Acc_Diff\"] = results_df[\"Train Accuracy\"] - results_df[ \"Test Accuracy\"]\n",
    "results_df[\"Train-Test F1_Diff\"] = results_df[\"Train F1\"] - results_df[ \"Test F1\"]\n",
    "results_df = results_df.sort_values(by=\"Test Acc_Diff\", ascending=False)\n",
    "\n",
    "print(\"\\nSummary of All Models:\")\n",
    "display(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7cde6a",
   "metadata": {},
   "source": [
    "Dan Millers reference metrics notebook:\n",
    "https://github.com/DMill31/applied-ml-miller/blob/main/notebooks/project05/ensemble-miller.ipynb\n",
    "\n",
    "Megan Chastain\n",
    "https://github.com/Megan-Chastain1/applied-ml-Chastain/blob/main/docs/project05/%20ensemble-Chastain.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bca8cdf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv - applied-ml-hrawp)",
   "language": "python",
   "name": "applied-ml-hrawp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
