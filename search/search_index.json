{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Applied ML Projects","text":"<p>Author: Aaron</p> <p>I have updated Project 3 which can be accessed by the link below.</p> <p>Projects index:</p> <ul> <li>Project 01: Title Here</li> <li>Project 02: Exploring the Titanic Dataset</li> <li>Project 03: Three Model Types with the Titanic Dataset</li> <li>Project 04: Title Here</li> </ul>"},{"location":"project01/","title":"Project 01","text":""},{"location":"project01/#overview","title":"Overview","text":"<p>Businesses and organizations often need to understand the relationships between different factors to make better decisions. For example, a company may want to predict the fuel efficiency of a car based on its weight and engine size or estimate home prices based on square footage and location. Regression analysis helps identify and quantify these relationships between numerical features, providing insights that can be used for forecasting and decision-making.</p> <p>This project demonstrates your ability to apply regression modeling techniques to a real-world dataset. You will: - Load and explore a dataset. - Choose and justify features for predicting a target variable. - Train a regression model and evaluate performance. - Compare multiple regression approaches. - Document your work in a structured Jupyter Notebook.</p>"},{"location":"project01/#dataset","title":"Dataset","text":"<p>Housing Prices Dataset (Predict home values based on features like square footage and location) - We use the built-in dataset from scikit-learn:    - <code>from sklearn.datasets import fetch_california_housing</code> - Additional dataset available on Kaggle:    - Kaggle Housing Prices </p>"},{"location":"project01/#python-library-for-machine-learning-scikit-learn","title":"Python Library for Machine Learning: scikit-learn","text":"<p>We use scikit-learn, built on NumPy, SciPy, and matplotlib    - Read more at https://scikit-learn.org/    - Scikit-learn supports classification, regression, and clustering.    - This project applies regression.</p>"},{"location":"project01/#professional-python-setup-and-workflow","title":"Professional Python Setup and Workflow","text":"<p>We follow professional Python practices.  Full instructions are available at https://github.com/denisecase/pro-analytics-02/. </p> <p>Important: VS Code + Pylance may fail to recognize installed packages in Jupyter notebooks. See the above guides for troubleshooting and solutions.  </p>"},{"location":"project01/#project-outline","title":"Project Outline","text":"<p>Machine learning projects follow a structured approach. We will use this approach throughout the course. </p> <p>Start your notebook professionally with: - a single top-level title - your name (or alias) - the date - a brief introduction that describes the problem and the dataset. - Import the external Python libraries used (e.g., pandas, numpy, matplotlib, seaborn, sklearn, etc.)</p> <p>Present your work in clearly numbered second-level and third-level headings</p>"},{"location":"project01/#section-1-load-and-explore-the-data","title":"Section 1. Load and Explore the Data","text":"<ul> <li>1.1 Load the dataset and display the first 10 rows.</li> <li>1.2 Check for missing values and display summary statistics.</li> </ul> <p>Analysis: What do you notice about the dataset? Are there any data issues?</p>"},{"location":"project01/#section-2-visualize-feature-distributions","title":"Section 2. Visualize Feature Distributions","text":"<ul> <li>2.1 Create histograms, boxplots, and scatterplots.</li> <li>2.2 Identify patterns or anomalies in feature distributions.</li> </ul> <p>Analysis: What patterns or anomalies do you see? Do any features stand out?</p>"},{"location":"project01/#section-3-feature-selection-and-justification","title":"Section 3. Feature Selection and Justification","text":"<ul> <li>3.1 Choose two input features for predicting the target.</li> <li>3.2 Justify your selection with reasoning.</li> </ul> <p>Analysis: Why did you choose these features? How might they impact predictions?</p>"},{"location":"project01/#section-4-train-a-linear-regression-model","title":"Section 4. Train a Linear Regression Model","text":"<ul> <li>4.1 Define X (features) and y (target).</li> <li>4.2 Train a Linear Regression model using Scikit-Learn.</li> <li>4.3 Report R^2, MAE, RMSE.</li> </ul> <p>Analysis: How well did the model perform? Any surprises in the results?</p> <p>See EXAMPLE_ANALYSIS for more.</p>"},{"location":"project01/#readmemd-required","title":"README.md (Required)","text":"<p>Include a professional README.md. Include: - a personalized title - an introduction to your project - a clickable link to your notebook file. - Instructions on how to set up your virtual environment and run your notebook locally.</p> <p>If starting with an assignment README, remove the parts you do not need to present your project.</p>"},{"location":"project01/EXAMPLE_ANALYSIS/","title":"Project 1 - Analysis","text":"<p>Your content here...</p>"},{"location":"project02/","title":"Project 02","text":""},{"location":"project02/#titanic-dataset-analysis","title":"Titanic Dataset Analysis","text":"<p>Author: AARON  Date: October, 29, 2025  Objective: Untilize the first four steps in the model creation process with the Titanic dataset.</p>"},{"location":"project02/#introduction","title":"Introduction","text":"<ul> <li>This project uses the Titanic dataset to Explore and Clean data, choose a feature to predict, and split the dataset into train and test subsets.</li> </ul>"},{"location":"project02/#note","title":"Note:","text":"<ul> <li>I think it is appropriate to have data examples and graphs in the notebook rather than copying into the README.  - Here I include the oultine of the project and reflections for summaries.</li> </ul>"},{"location":"project02/#include-imports","title":"Include Imports","text":""},{"location":"project02/#section-1-load-and-explore-the-data","title":"Section 1. Load and Explore the Data","text":""},{"location":"project02/#11-load-the-dataset-and-display-basic-information","title":"1.1 Load the dataset and display basic information","text":""},{"location":"project02/#12-check-for-missing-values-and-display-summary-statistics","title":"1.2 Check for missing values and display summary statistics","text":""},{"location":"project02/#section-2-data-exploration-and-preparation","title":"Section 2. Data Exploration and Preparation","text":""},{"location":"project02/#21-explore-data-patterns-and-distributions","title":"2.1 Explore Data Patterns and Distributions","text":""},{"location":"project02/#reflection-21","title":"Reflection 2.1:","text":"<ul> <li>What patterns or anomalies do you notice?  <ol> <li>There were a lot of very young children aboard.  </li> <li>There must have been some reason third class had such a high mortality rate.</li> </ol> </li> <li>Do any features stand out as potential predictors? It looks like higher fares were paid by women.</li> <li>Are there any visible class imbalances? Younger people appear to be in third class.</li> </ul>"},{"location":"project02/#22-handle-missing-values-and-clean-data","title":"2.2 Handle Missing Values and Clean Data","text":""},{"location":"project02/#23-feature-engineering","title":"2.3 Feature Engineering","text":""},{"location":"project02/#reflection-23","title":"Reflection 2.3","text":"<ul> <li>Why might family size be a useful feature for predicting survival?  </li> <li>This may help if a families were together.  I suspect there were seperations though.</li> <li>Why convert categorical data to numeric? It helps for mathematical cacluations for models and one-hop encoding.</li> </ul>"},{"location":"project02/#section-3-feature-selection-and-justification","title":"Section 3. Feature Selection and Justification","text":""},{"location":"project02/#31-choose-features-and-target","title":"3.1 Choose features and target","text":""},{"location":"project02/#32-define-x-and-y","title":"3.2 Define X and y","text":"<ul> <li>Input features: age, fare, pclass, sex, family_size</li> <li>Target: survived</li> </ul>"},{"location":"project02/#reflection-3","title":"Reflection 3:","text":"<ul> <li>Why are these features selected?  These were determined in anaylsis above to have an impact.</li> <li>Are there any features that are likely to be highly predictive of survival?  I think class and sex will be the most predictive.</li> </ul>"},{"location":"project02/#section-4-splitting","title":"Section 4. Splitting","text":"<ul> <li>Split the data into training and test sets using train_test_split first and StratifiedShuffleSplit second. Compare.</li> </ul>"},{"location":"project02/#41-basic-traintest-split","title":"4.1 Basic Train/Test split","text":"<p>Original Class Distribution:</p> <ul> <li>Class 3    0.551066</li> <li>Class 1    0.242424</li> <li>Class 2    0.206510</li> </ul> <p>Train Set Class Distribution:</p> <ul> <li>Class 3    0.557584</li> <li>Class 1    0.233146</li> <li>Class 2    0.209270</li> </ul> <p>Test Set Class Distribution:</p> <ul> <li>Class 3    0.525140</li> <li>Class 1    0.279330</li> <li>Class 2    0.195531</li> </ul>"},{"location":"project02/#42-stratified-traintest-split","title":"4.2 Stratified Train/Test split","text":"<p>Original Class Distribution:</p> <ul> <li>Class 3    0.551066</li> <li>Class 1    0.242424</li> <li>Class 2    0.206510</li> </ul> <p>Train Set Class Distribution:</p> <ul> <li>Class 3    0.561798</li> <li>Class 1    0.227528</li> <li>Class 2    0.210674</li> </ul> <p>Test Set Class Distribution:</p> <ul> <li>Class 3    0.508380</li> <li>Class 1    0.301676</li> <li>Class 2    0.189944</li> </ul>"},{"location":"project02/#43-compare-results","title":"4.3 Compare Results","text":""},{"location":"project02/#44-reflection-4","title":"4.4 Reflection 4","text":"<ul> <li>Why might stratification improve model performance?  I don't think stratification would improve model performance.  It looks to have a distribution less like the original class distribution than the basic class distribution. </li> <li>How close are the training and test distributions to the original dataset?  The stratisfied results look farther away from the original distribution for both the training and test set disbributions as compared to the basic one.</li> <li>Which split method produced better class balance?  The basic Train method looks to have a better class distribution to the original class distribution.</li> </ul>"},{"location":"project03/","title":"Project 3: Titanic Dataset Analysis","text":"<p>Author: AARON  Date: November, 4, 2025  Objective: Setup three model types, Decision Tree, Support Vector Machine, and Neural Network and use these to predict survival rate on the Titanic dataset.</p>"},{"location":"project03/#introduction","title":"Introduction","text":"<p>This project uses the Titanic dataset to Explore and Clean data, choose a feature to predict, and split the dataset into train and test subsets. Setup three model types, Decision Tree, Support Vector Machine, and Neural Network and use these to predict survival rate on the Titanic dataset.  I use three differet test cases with specific features of 'alone', 'age', and 'age' + 'family size'. Compare the output of these models and test cases against the others and see which, if any, predict survival rate better.</p>"},{"location":"project03/#section-3-feature-selection-and-justification","title":"Section 3. Feature Selection and Justification","text":""},{"location":"project03/#31-choose-features-and-target","title":"3.1 Choose features and target","text":"<p>Select two or more input features (numerical for regression, numerical and/or categorical for classification) Use survived as the target.  We will do three input cases like the example. </p> <p>Case 1:  input features: alone target: survived</p> <p>Case 2: input features - age target: survived</p> <p>Case 3: input features -  age and family_size  target: survived</p>"},{"location":"project03/#reflection-3","title":"Reflection 3:","text":"<p>Why are these features selected?  These were selected based on reviewing the overview of the data. Are there any features that are likely to be highly predictive of survival?  I think age will be the most predictive.</p>"},{"location":"project03/#43-predict-and-evaluate-model-performance-decisiont-tree","title":"4.3 Predict and Evaluate Model Performance (Decisiont Tree)","text":"Model Type Case Features Used Accuracy Precision Recall F1-Score Notes Decision Tree Case 1 alone 63% 64% 63% 63% - Case 2 age 61% 58% 61% 55% - Case 3 age + family_size 59% 57% 59% 58% -"},{"location":"project03/#reflection-4","title":"Reflection 4:","text":"<p>How well did the different cases perform?  I for sure could see a disitction with the feaure 'alone' showing the best results. Are there any surprising results?  I was very suprised to see the 'alone' feature being a better predictor of survival than the age based features. Which inputs worked better? The 'alone' input worked the best.</p>"},{"location":"project03/#section-5-compare-alternative-models-svc-nn","title":"Section 5. Compare Alternative Models (SVC, NN)","text":"Model Type Case Features Used Accuracy Precision Recall F1-Score Notes Decision Tree Case 1 alone 63% 64% 63% 63% - Case 2 age 61% 58% 61% 55% - Case 3 age + family_size 59% 57% 59% 58% - ---------------------- -------- ------------------- ---------- ----------- -------- ----------- ------- SVM (RBF Kernel) Case 1 alone 63% 64% 63% 63% - Case 2 age 63% 66% 63% 52% - Case 3 age + family_size 63% 66% 63% 52% - ---------------------- -------- ------------------- ---------- ----------- -------- ----------- ------- Neural Network (MLP) Case 1 alone --- ---- --- -- - Case 2 age --- ---- --- -- - Case 3 age + family_size 66% 65% 66% 65% -"},{"location":"project03/#reflection-5","title":"Reflection 5:","text":"<p>How well did each of these new models/cases perform?  'The 'alone' case again performed the best in the SVM model type.  But the distinction between the three SVM cases narrowed as compared to the Decision Tree.  The Neural Network outperformed every other model. Are there any surprising results or insights?  I am surprised case 3 was so much better than the same case in the Decision Tree. Why might one model outperform the others?  I think the Neural Network performed better since it had two variables to work with and had feedback from both into each node.</p>"},{"location":"project03/#section-6-final-thoughts-insights","title":"Section 6. Final Thoughts &amp; Insights","text":"<p>At first I was a little discouraged at the accuracy of the models and other parameters.  It seemed like just knowing if a passenger was alone or not told most of the tale.  But when I worked with the Neural Network I saw noticeable improvement in the results.  I was glad to see that.  These differences can be seen in the table below. I look forward to using Neural Networks in the future for classification models.</p>"},{"location":"project04/","title":"Project 04","text":""}]}